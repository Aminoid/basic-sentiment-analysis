[2017-01-19 23:30:22,810] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2017-01-19 23:30:44,813] TRACE Controller 0 epoch 8 started leader election for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:30:44,832] ERROR Controller 0 epoch 8 initiated state change for partition [twitterStream,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [twitterStream,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:335)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:166)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:50)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:48)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:684)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.controller.KafkaController.startup(KafkaController.scala:680)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:200)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2017-01-19 23:30:44,835] TRACE Controller 0 epoch 8 started leader election for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:30:44,849] ERROR Controller 0 epoch 8 initiated state change for partition [twitterstream,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [twitterstream,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:335)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:166)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:50)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:48)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:684)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.controller.KafkaController.startup(KafkaController.scala:680)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:200)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2017-01-19 23:30:55,206] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:7) to broker 0 for partition twitterstream-0 (state.change.logger)
[2017-01-19 23:30:55,207] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:7) to broker 0 for partition twitterStream-0 (state.change.logger)
[2017-01-19 23:30:55,284] TRACE Controller 0 epoch 8 changed state of replica 0 for partition [twitterStream,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2017-01-19 23:30:55,285] TRACE Controller 0 epoch 8 changed state of replica 0 for partition [twitterstream,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2017-01-19 23:30:55,302] TRACE Controller 0 epoch 8 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:7) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:30:55,302] TRACE Controller 0 epoch 8 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:7) to broker 0 for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:30:55,310] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:7) to broker 0 for partition twitterstream-0 (state.change.logger)
[2017-01-19 23:30:55,310] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:7) to broker 0 for partition twitterStream-0 (state.change.logger)
[2017-01-19 23:30:55,311] TRACE Controller 0 epoch 8 started leader election for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:30:55,336] TRACE Controller 0 epoch 8 elected leader 0 for Offline partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:30:55,338] TRACE Controller 0 epoch 8 changed partition [twitterStream,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2017-01-19 23:30:55,339] TRACE Controller 0 epoch 8 started leader election for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:30:55,349] TRACE Controller 0 epoch 8 elected leader 0 for Offline partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:30:55,349] TRACE Controller 0 epoch 8 changed partition [twitterstream,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2017-01-19 23:30:55,350] TRACE Controller 0 epoch 8 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:8) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:30:55,350] TRACE Controller 0 epoch 8 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:8) to broker 0 for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:30:55,350] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:8) to broker 0 for partition twitterstream-0 (state.change.logger)
[2017-01-19 23:30:55,351] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:8) to broker 0 for partition twitterStream-0 (state.change.logger)
[2017-01-19 23:31:05,202] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) for partition twitterStream-0 in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 0 (state.change.logger)
[2017-01-19 23:31:05,203] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) for partition twitterstream-0 in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 0 (state.change.logger)
[2017-01-19 23:31:05,205] TRACE Controller 0 epoch 8 received response {error_code=0} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-19 23:31:05,257] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@4d0cacd2 correlation id 1 from controller 0 epoch 8 for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:31:05,257] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@494a4bbe correlation id 1 from controller 0 epoch 8 for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:31:05,282] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 8 starting the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:31:05,282] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 8 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:31:05,351] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 8 with correlation id 1 for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:31:05,351] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 8 with correlation id 1 for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:31:05,353] TRACE Broker 0 completed LeaderAndIsr request correlationId 1 from controller 0 epoch 8 for the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:31:05,353] TRACE Broker 0 completed LeaderAndIsr request correlationId 1 from controller 0 epoch 8 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:31:05,364] TRACE Controller 0 epoch 8 received response {error_code=0,partitions=[{topic=twitterstream,partition=0,error_code=0},{topic=twitterStream,partition=0,error_code=0}]} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-19 23:31:05,366] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) for partition twitterStream-0 in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 2 (state.change.logger)
[2017-01-19 23:31:05,366] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) for partition twitterstream-0 in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 2 (state.change.logger)
[2017-01-19 23:31:05,367] TRACE Controller 0 epoch 8 received response {error_code=0} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-19 23:31:05,367] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@71af7f00 correlation id 3 from controller 0 epoch 8 for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:31:05,368] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@2e24b77d correlation id 3 from controller 0 epoch 8 for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:31:05,368] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 8 starting the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:31:05,368] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 8 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:31:05,370] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 8 for partition [twitterStream,0] since it is already the leader for the partition. (state.change.logger)
[2017-01-19 23:31:05,370] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 8 for partition [twitterstream,0] since it is already the leader for the partition. (state.change.logger)
[2017-01-19 23:31:05,370] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 8 for the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-19 23:31:05,371] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 8 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-19 23:31:05,371] TRACE Controller 0 epoch 8 received response {error_code=0,partitions=[{topic=twitterstream,partition=0,error_code=0},{topic=twitterStream,partition=0,error_code=0}]} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-19 23:31:05,387] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:8),ReplicationFactor:1),AllReplicas:0) for partition twitterStream-0 in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 4 (state.change.logger)
[2017-01-19 23:31:05,387] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:8),ReplicationFactor:1),AllReplicas:0) for partition twitterstream-0 in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 4 (state.change.logger)
[2017-01-19 23:31:05,388] TRACE Controller 0 epoch 8 received response {error_code=0} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
