[2017-01-21 15:16:22,370] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2017-01-21 15:16:46,552] TRACE Controller 0 epoch 16 started leader election for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:16:46,569] ERROR Controller 0 epoch 16 initiated state change for partition [twitterStream,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [twitterStream,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:335)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:166)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:50)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:48)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:684)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.controller.KafkaController.startup(KafkaController.scala:680)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:200)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2017-01-21 15:16:46,573] TRACE Controller 0 epoch 16 started leader election for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:16:46,583] ERROR Controller 0 epoch 16 initiated state change for partition [twitterstream,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [twitterstream,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:335)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:166)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:50)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:48)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:684)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:680)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.controller.KafkaController.startup(KafkaController.scala:680)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:200)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2017-01-21 15:16:56,946] TRACE Controller 0 epoch 16 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:11,ControllerEpoch:14) to broker 0 for partition twitterstream-0 (state.change.logger)
[2017-01-21 15:16:56,946] TRACE Controller 0 epoch 16 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:9,ControllerEpoch:14) to broker 0 for partition twitterStream-0 (state.change.logger)
[2017-01-21 15:16:56,982] TRACE Controller 0 epoch 16 changed state of replica 0 for partition [twitterStream,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2017-01-21 15:16:56,983] TRACE Controller 0 epoch 16 changed state of replica 0 for partition [twitterstream,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2017-01-21 15:16:56,986] TRACE Controller 0 epoch 16 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:11,ControllerEpoch:14) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:16:56,986] TRACE Controller 0 epoch 16 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:9,ControllerEpoch:14) to broker 0 for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:16:56,992] TRACE Controller 0 epoch 16 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:11,ControllerEpoch:14) to broker 0 for partition twitterstream-0 (state.change.logger)
[2017-01-21 15:16:56,992] TRACE Controller 0 epoch 16 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:9,ControllerEpoch:14) to broker 0 for partition twitterStream-0 (state.change.logger)
[2017-01-21 15:16:56,993] TRACE Controller 0 epoch 16 started leader election for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:16:57,009] TRACE Controller 0 epoch 16 elected leader 0 for Offline partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:16:57,011] TRACE Controller 0 epoch 16 changed partition [twitterStream,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2017-01-21 15:16:57,012] TRACE Controller 0 epoch 16 started leader election for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:16:57,020] TRACE Controller 0 epoch 16 elected leader 0 for Offline partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:16:57,021] TRACE Controller 0 epoch 16 changed partition [twitterstream,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2017-01-21 15:16:57,021] TRACE Controller 0 epoch 16 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:12,ControllerEpoch:16) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:16:57,022] TRACE Controller 0 epoch 16 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:16) to broker 0 for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:16:57,022] TRACE Controller 0 epoch 16 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:12,ControllerEpoch:16) to broker 0 for partition twitterstream-0 (state.change.logger)
[2017-01-21 15:16:57,022] TRACE Controller 0 epoch 16 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:16) to broker 0 for partition twitterStream-0 (state.change.logger)
[2017-01-21 15:17:01,913] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:9,ControllerEpoch:14),ReplicationFactor:1),AllReplicas:0) for partition twitterStream-0 in response to UpdateMetadata request sent by controller 0 epoch 16 with correlation id 0 (state.change.logger)
[2017-01-21 15:17:01,914] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:11,ControllerEpoch:14),ReplicationFactor:1),AllReplicas:0) for partition twitterstream-0 in response to UpdateMetadata request sent by controller 0 epoch 16 with correlation id 0 (state.change.logger)
[2017-01-21 15:17:01,917] TRACE Controller 0 epoch 16 received response {error_code=0} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-21 15:17:01,976] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@63eb7d6 correlation id 1 from controller 0 epoch 16 for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:17:01,976] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@2c292cce correlation id 1 from controller 0 epoch 16 for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:17:02,014] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 16 starting the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:17:02,014] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 16 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:17:02,558] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 16 with correlation id 1 for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:17:02,558] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 16 with correlation id 1 for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:17:02,563] TRACE Broker 0 completed LeaderAndIsr request correlationId 1 from controller 0 epoch 16 for the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:17:02,563] TRACE Broker 0 completed LeaderAndIsr request correlationId 1 from controller 0 epoch 16 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:17:02,577] TRACE Controller 0 epoch 16 received response {error_code=0,partitions=[{topic=twitterstream,partition=0,error_code=0},{topic=twitterStream,partition=0,error_code=0}]} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-21 15:17:02,578] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:9,ControllerEpoch:14),ReplicationFactor:1),AllReplicas:0) for partition twitterStream-0 in response to UpdateMetadata request sent by controller 0 epoch 16 with correlation id 2 (state.change.logger)
[2017-01-21 15:17:02,578] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:11,ControllerEpoch:14),ReplicationFactor:1),AllReplicas:0) for partition twitterstream-0 in response to UpdateMetadata request sent by controller 0 epoch 16 with correlation id 2 (state.change.logger)
[2017-01-21 15:17:02,579] TRACE Controller 0 epoch 16 received response {error_code=0} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-21 15:17:02,580] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@734f7c05 correlation id 3 from controller 0 epoch 16 for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:17:02,580] TRACE Broker 0 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState@7d888c1c correlation id 3 from controller 0 epoch 16 for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:17:02,580] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 16 starting the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:17:02,580] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 16 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:17:02,582] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 16 for partition [twitterStream,0] since it is already the leader for the partition. (state.change.logger)
[2017-01-21 15:17:02,583] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 16 for partition [twitterstream,0] since it is already the leader for the partition. (state.change.logger)
[2017-01-21 15:17:02,583] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 16 for the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2017-01-21 15:17:02,583] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 16 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2017-01-21 15:17:02,584] TRACE Controller 0 epoch 16 received response {error_code=0,partitions=[{topic=twitterstream,partition=0,error_code=0},{topic=twitterStream,partition=0,error_code=0}]} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
[2017-01-21 15:17:02,585] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:16),ReplicationFactor:1),AllReplicas:0) for partition twitterStream-0 in response to UpdateMetadata request sent by controller 0 epoch 16 with correlation id 4 (state.change.logger)
[2017-01-21 15:17:02,585] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:12,ControllerEpoch:16),ReplicationFactor:1),AllReplicas:0) for partition twitterstream-0 in response to UpdateMetadata request sent by controller 0 epoch 16 with correlation id 4 (state.change.logger)
[2017-01-21 15:17:02,586] TRACE Controller 0 epoch 16 received response {error_code=0} for a request sent to broker 192.168.0.2:9092 (id: 0 rack: null) (state.change.logger)
